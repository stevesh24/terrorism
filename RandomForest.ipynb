{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This describes the Random Forest analysis. \n",
    "outcome: gname, 63 categories, each having at least 150 entries\n",
    "features: 35, listed in final_data_list.xlsx\n",
    "rows (entries): 38251 total entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Y_in.csv had the outcome as 1 column with 63 categories. For Random Forest\n",
    "# the outcomes were recoded as 63 columns and put into Y_out.xlsx\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "\n",
    "home = r\"C:\\Users\\ibshi\\Desktop\\startup.ml\\challenge 2\\global terrorism\\data\"\n",
    "infile = home + r\"\\Y_in.csv\"\n",
    "Y_in = pd.read_csv(infile,header=None)\n",
    "\n",
    "temp = Y_in[0].value_counts()\n",
    "terrlist = list(temp.index)\n",
    "nrows = len(Y_in.index)\n",
    "ncols = len(terrlist)\n",
    "Y_out = pd.DataFrame(np.zeros((nrows,ncols)),columns=terrlist)\n",
    "Y_temp=pd.concat([Y_in,Y_out],axis=1)\n",
    "\n",
    "for terr in terrlist:\n",
    "    Y_temp[terr][Y_temp[0]==terr]=1\n",
    "\n",
    "Y_temp.drop('0',inplace=True,axis=1)\n",
    "Y_out = Y_temp\n",
    "\n",
    "outfile = home + r\"\\Y_out.xlsx\"\n",
    "Y_out.to_excel(outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This runs Random Forest on the full model, default settings\n",
    "# the data were divided in half for the training and test datasets\n",
    "\n",
    "# the results from the full model\n",
    "# accuracy test = 0.813091441\n",
    "# accuracy train = 0.983057938\n",
    "# The full results are in <results random forest.xlsx>.\n",
    "# This result is the first line of <results random forest.xlsx>.\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "#home = r\"C:\\Users\\ibshi\\Desktop\\startup.ml\\challenge 2\\global terrorism\\data\"\n",
    "infile = home + r\"\\final_data.xlsx\"\n",
    "final_data = pd.read_excel(infile)\n",
    "\n",
    "infile = home + r\"\\Y_out.xlsx\"\n",
    "Y = pd.read_excel(infile)\n",
    "\n",
    "# You have to make the categorical variables into a series of dummy variables. \n",
    "\n",
    "catlist = ['country',\n",
    "'region',\n",
    "'attacktype1',\n",
    "'attacktype2',\n",
    "'targtype1',\n",
    "'targsubtype1',\n",
    "'claimmode',\n",
    "'weaptype1',\n",
    "'WeapRecode1',\n",
    "'weaptype2',\n",
    "'WeapRecode2',\n",
    "'hostkidoutcome']\n",
    "\n",
    "for cat in catlist:\n",
    "    hold = pd.get_dummies(final_data[cat])\n",
    "    final_data = pd.concat([final_data, hold], axis=1)\n",
    "\n",
    "final_data.drop(catlist,inplace=True,axis=1)\n",
    "\n",
    "#impute NaN values (replace with mean or median)\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=1)\n",
    "imputed_data = pd.DataFrame(imp.fit_transform(final_data))\n",
    "\n",
    "# create training and test datasets, 0.5 training and 0.5 test\n",
    "\n",
    "prop_train = 0.5\n",
    "numtrain = int(prop_train* len(Y))\n",
    "\n",
    "# randomize whether entry is in test or training\n",
    "\n",
    "sorter = pd.DataFrame(data=np.zeros(len(Y)),columns=['sorter'])\n",
    "sorter.sorter[0:numtrain-1] = 1\n",
    "np.random.shuffle(sorter.sorter)\n",
    "\n",
    "t_data = pd.concat([sorter,imputed_data],axis=1)\n",
    "t_Y = pd.concat([sorter,Y],axis=1)\n",
    "\n",
    "train = t_data[t_data.sorter == 1]\n",
    "trainY = t_Y[t_Y.sorter == 1]\n",
    "\n",
    "test = t_data[t_data.sorter == 0]\n",
    "testY = t_Y[t_Y.sorter == 0]\n",
    "\n",
    "train.drop(['sorter'],inplace=True,axis=1)\n",
    "trainY.drop(['sorter'],inplace=True,axis=1)\n",
    "test.drop(['sorter'],inplace=True,axis=1)\n",
    "testY.drop(['sorter'],inplace=True,axis=1)\n",
    "\n",
    "# Run Random Forest\n",
    "\n",
    "RF = sklearn.ensemble.RandomForestClassifier()\n",
    "\n",
    "RF.fit(train,trainY)\n",
    "out = RF.predict(test)\n",
    "outDF = pd.DataFrame(out)\n",
    "sc_test = RF.score(test,testY)\n",
    "print \"accuracy on test set\"\n",
    "print sc_test\n",
    "sc_train = RF.score(train,trainY)\n",
    "print \"accuracy on train set\"\n",
    "print sc_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This runs the Random Forest with the ability to drop features from the\n",
    "# analysis (in the droplist). This code was run to tune the RF model,\n",
    "# and the results can be found in <results random forest.xlsx>. Changing\n",
    "# the number of estimators did not seem to have an effect.  Dropping\n",
    "# certain features somewhat improved the model performance. This\n",
    "# tuning resulted in the model found below, and summarized below:\n",
    "\n",
    "# features in best model:\n",
    "# iyear\n",
    "# iday\n",
    "# Weekday (added)\n",
    "# country\n",
    "# region\n",
    "# nkill\n",
    "# nhostkid\n",
    "# ransom\n",
    "# INT_LOG\n",
    "# INT_IDEO\n",
    "\n",
    "# The best model was run 20 times, with the following results\n",
    "# can be found in <results random forest.xlsx>.\n",
    "# mean accuracy, test = 0.86838\n",
    "# sd accuracy, test   = 0.00261\n",
    "# mean accuracy, training = 0.98068\n",
    "# sd accuracy, training   = 0.00112\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "home = r\"C:\\Users\\ibshi\\Desktop\\startup.ml\\challenge 2\\global terrorism\\data\"\n",
    "infile = home + r\"\\final_data.xlsx\"\n",
    "final_data = pd.read_excel(infile)\n",
    "\n",
    "infile = home + r\"\\Y_out.xlsx\"\n",
    "Y = pd.read_excel(infile)\n",
    "\n",
    "# determine which feature to be dropped\n",
    "\n",
    "droplist = ['weaptype1','weaptype2','WeapRecode1','WeapRecode2','attacktype2',\n",
    "'hostkidoutcome','claimmode','targsubtype1','targtype1','attacktype1',\n",
    "'imonth','crit1','crit2','crit3','multiple','success','suicide','nperps',\n",
    "'nperpcap','claimed','nwound','propextent','ndays','nreleased','INT_MISC']\n",
    "\n",
    "final_data.drop(droplist,inplace=True,axis=1)\n",
    "\n",
    "# You have to make the categorical variables into a series of dummy variables. \n",
    "\n",
    "catlist = ['country',\n",
    "'region']\n",
    "\n",
    "for cat in catlist:\n",
    "    hold = pd.get_dummies(final_data[cat])\n",
    "    final_data = pd.concat([final_data, hold], axis=1)\n",
    "\n",
    "final_data.drop(catlist,inplace=True,axis=1)\n",
    "\n",
    "#impute NaN values (replace with mean or median)\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=1)\n",
    "imputed_data = pd.DataFrame(imp.fit_transform(final_data))\n",
    "\n",
    "# randomize whether entry is in test or training\n",
    "\n",
    "prop_train = 0.5\n",
    "numtrain = int(prop_train* len(Y))\n",
    "\n",
    "sorter = pd.DataFrame(data=np.zeros(len(Y)),columns=['sorter'])\n",
    "sorter.sorter[0:numtrain-1] = 1\n",
    "np.random.shuffle(sorter.sorter)\n",
    "\n",
    "t_data = pd.concat([sorter,imputed_data],axis=1)\n",
    "t_Y = pd.concat([sorter,Y],axis=1)\n",
    "\n",
    "train = t_data[t_data.sorter == 1]\n",
    "trainY = t_Y[t_Y.sorter == 1]\n",
    "\n",
    "test = t_data[t_data.sorter == 0]\n",
    "testY = t_Y[t_Y.sorter == 0]\n",
    "\n",
    "train.drop(['sorter'],inplace=True,axis=1)\n",
    "trainY.drop(['sorter'],inplace=True,axis=1)\n",
    "test.drop(['sorter'],inplace=True,axis=1)\n",
    "testY.drop(['sorter'],inplace=True,axis=1)\n",
    "\n",
    "# Run Random Forest\n",
    "\n",
    "RF = sklearn.ensemble.RandomForestClassifier()\n",
    "\n",
    "RF.fit(train,trainY)\n",
    "out = RF.predict(test)\n",
    "outDF = pd.DataFrame(out)\n",
    "sc_test = RF.score(test,testY)\n",
    "print \"accuracy on test set\"\n",
    "print sc_test\n",
    "sc_train = RF.score(train,trainY)\n",
    "print \"accuracy on train set\"\n",
    "print sc_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In this section changes to the model are considered\n",
    "\n",
    "# 1. One aspect is that I used a limited set of available features.  \n",
    "#    Adding more features might have improved performance.  However,\n",
    "#    as the the model either improved or remained the same when\n",
    "#    generally removing features from the original set of 35, it \n",
    "#    doesn't seem likely that this would lead to substantial improvement. \n",
    "\n",
    "# 2. Looking over the dropped features, it seems that 'city' might be\n",
    "#    a useful feature to add, given the use of 'country' and 'region'\n",
    "#    in the final model. \n",
    "\n",
    "home = r\"C:\\Users\\ibshi\\Desktop\\startup.ml\\challenge 2\\global terrorism\\data\"\n",
    "infile = home + r\"\\globalterrorismdb_0616dist.xlsx\"\n",
    "indata = pd.read_excel(infile)\n",
    "\n",
    "inseries = indata.city[pd.notnull(indata.city)]\n",
    "unique_city = list(np.unique(inseries))\n",
    "print len(unique_city)\n",
    "\n",
    "#    However, a check of the number of unique cities in the dataset\n",
    "#    gives 31324, which seems too large to be useful.\n",
    "\n",
    "# 3. There were a number of unstructured text fields: 'summary','motive',\n",
    "#    'ransomnote', and 'addnotes'\n",
    "\n",
    "#    The code below creates lists of unique words for each of these\n",
    "#    fields.  There are too many unique words for these to be used \n",
    "#    unprocessed. However, perhaps some processing (i.e., for certain\n",
    "#    key words, or by language) might lead to useful new features.\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "\n",
    "def find_unique(t):\n",
    "    holdlist =list('a')\n",
    "    for i in list(t.index):\n",
    "        temp = t[i]\n",
    "        temp = temp.lower()\n",
    "        templist = re.findall('[a-z]+',temp)\n",
    "        holdlist = holdlist + templist   \n",
    "    unique_list = list(np.unique(holdlist))\n",
    "    return unique_list\n",
    "    \n",
    "home = r\"C:\\Users\\ibshi\\Desktop\\startup.ml\\challenge 2\\global terrorism\\data\"\n",
    "infile = home + r\"\\globalterrorismdb_0616dist.xlsx\"\n",
    "indata = pd.read_excel(infile)\n",
    "\n",
    "inSeries = indata.motive[pd.notnull(indata.motive)]\n",
    "outlist = find_unique(inSeries)\n",
    "outfile = home + r\"\\unique_motive_list.csv\"\n",
    "np.savetxt(outfile,outlist,delimiter=\",\", fmt='%s')\n",
    "#print len(outlist)\n",
    "\n",
    "inSeries = indata.summary[pd.notnull(indata.summary)]\n",
    "outlist = find_unique(inSeries)\n",
    "outfile = home + r\"\\unique_summary_list.csv\"\n",
    "np.savetxt(outfile,outlist,delimiter=\",\", fmt='%s')\n",
    "\n",
    "inSeries = indata.ransomnote[pd.notnull(indata.ransomnote)]\n",
    "outlist = find_unique(inSeries)\n",
    "outfile = home + r\"\\unique_ransomnote_list.csv\"\n",
    "np.savetxt(outfile,outlist,delimiter=\",\", fmt='%s')\n",
    "\n",
    "inSeries = indata.addnotes[pd.notnull(indata.addnotes)]\n",
    "outlist = find_unique(inSeries)\n",
    "outfile = home + r\"\\unique_addnotes_list.csv\"\n",
    "np.savetxt(outfile,outlist,delimiter=\",\", fmt='%s')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
